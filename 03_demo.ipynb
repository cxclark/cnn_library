{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Demo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Notebooks\n",
    "[01_data_visualization](#01_data_visualization.ipynb)  \n",
    "[02_formulas](#02_formulas.ipynb)  \n",
    "[03_demo](03_demo.ipynb)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This Notebook's Contents\n",
    "[Model 1 Demo](#Model-1-Demo)  \n",
    "[Model 2 Demo](#Model-2-Demo)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import CIFAR-10 training data.\n",
    "from tensorflow.keras.datasets import cifar10\n",
    "(X_train, y_train), (X_test, y_test) = cifar10.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X_train: (50000, 32, 32, 3)\n",
      "Shape of X_test: (10000, 32, 32, 3)\n",
      "Shape of y_train: (50000, 1)\n",
      "Shape of y_test: (10000, 1)\n"
     ]
    }
   ],
   "source": [
    "# Display the shapes of the data.\n",
    "print(f'Shape of X_train: {X_train.shape}')\n",
    "print(f'Shape of X_test: {X_test.shape}')\n",
    "print(f'Shape of y_train: {y_train.shape}')\n",
    "print(f'Shape of y_test: {y_test.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the required modules.\n",
    "from hive_ml.layers.activation import ReluLayer\n",
    "from hive_ml.layers.convolution import ConvolutionLayer\n",
    "from hive_ml.layers.pooling import PoolLayer\n",
    "from hive_ml.layers.flatten import Flatten\n",
    "from hive_ml.layers.dense import DenseLayer\n",
    "from hive_ml.layers.loss import SoftmaxLayer\n",
    "from hive_ml.network import Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Downsize data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Downsize the training data in the interest of time.\n",
    "X_train = X_train[ :128, :, :, :]\n",
    "y_train = y_train[ :128, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Downsize test data.\n",
    "X_test = X_test[:100, :, :, :]\n",
    "y_test = y_test[:100, :]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model 1 Demo\n",
    "### CONV => RELU => POOL => FLATTEN => DENSE => DENSE => SOFTMAX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate a model.\n",
    "model1 = Model(\n",
    "    ConvolutionLayer(filters=3, filter_size=3, padding=1, stride=1),\n",
    "    ReluLayer(),\n",
    "    PoolLayer(filter_size=2, stride=2, mode='max'),\n",
    "    Flatten(),\n",
    "    DenseLayer(units=100),\n",
    "    DenseLayer(units=10),\n",
    "    SoftmaxLayer()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running epoch: 1\n",
      "Time to train on 128 examples: 10.01 seconds.\n",
      "Loss epoch 1: 2.943\n",
      "Accuracy epoch 1: 14.844%\n"
     ]
    }
   ],
   "source": [
    "# Train the model.\n",
    "model1.train(X_train, y_train, 0.003, batch_size=64, epochs=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### *Loss when kicking off training should be $-log\\frac{1}{NumOfClasses}$, or ~2.3 for CIFAR-10, so good start*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((100, 32, 32, 3), (100, 1))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Print shapes.\n",
    "X_test.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions.\n",
    "predictions = model1.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 100)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Print shapes.\n",
    "predictions.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transpose the predictions  from (num_classes, m) to (m, num_classes)\n",
    "predictions = predictions.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[3.05477281e-02, 1.51285033e-07, 7.34422668e-01, 6.89410034e-04,\n",
       "        1.14254103e-09, 1.06031105e-01, 1.25331119e-02, 6.29248389e-08,\n",
       "        9.35880172e-06, 1.15766403e-01],\n",
       "       [6.34242471e-08, 3.50296140e-06, 3.46477340e-04, 5.29085231e-05,\n",
       "        2.12623462e-06, 8.01801124e-07, 1.18287198e-01, 8.11536936e-08,\n",
       "        8.81031356e-01, 2.75484247e-04],\n",
       "       [9.64907643e-05, 8.17355523e-06, 3.08687870e-01, 1.29447146e-02,\n",
       "        8.41709295e-09, 6.14513813e-01, 6.27183522e-02, 2.06946202e-05,\n",
       "        1.54788790e-07, 1.00972829e-03]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display the probability vectors for the first few images.\n",
    "# Every probability vector should add up to 1.\n",
    "predictions[:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 11.0%\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model.\n",
    "model1.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model 2 Demo\n",
    "### CONV => RELU => POOL => CONV => RELU => POOL => FLATTEN => DENSE => DENSE => SOFTMAX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate a model.\n",
    "model2 = Model(\n",
    "    ConvolutionLayer(filters=5, filter_size=3, padding=1, stride=1),\n",
    "    ReluLayer(),\n",
    "    PoolLayer(filter_size=2, stride=2, mode='max'),\n",
    "    ConvolutionLayer(filters=7, filter_size=5, padding=2, stride=1),\n",
    "    ReluLayer(),\n",
    "    PoolLayer(filter_size=2, stride=2, mode='max'),\n",
    "    Flatten(),\n",
    "    DenseLayer(units=200),\n",
    "    DenseLayer(units=100),\n",
    "    DenseLayer(units=10),\n",
    "    SoftmaxLayer()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running epoch: 1\n",
      "Time to train on 128 examples: 22.16 seconds.\n",
      "Loss epoch 1: 2.529\n",
      "Accuracy epoch 1: 9.375%\n"
     ]
    }
   ],
   "source": [
    "# Train the model.\n",
    "model2.train(X_train, y_train, 0.003, batch_size=64, epochs=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions.\n",
    "predictions = model2.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 100)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Print shape of predictions.\n",
    "predictions.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transpose the predictions  from (num_classes, m) to (m, num_classes).\n",
    "predictions = predictions.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.21498511, 0.04586393, 0.07094227, 0.13371353, 0.08156846,\n",
       "        0.02002535, 0.1195642 , 0.09124961, 0.0920763 , 0.13001124],\n",
       "       [0.05335689, 0.09721181, 0.07436768, 0.10554796, 0.20471735,\n",
       "        0.09703858, 0.06451661, 0.07716188, 0.0321318 , 0.19394946],\n",
       "       [0.07766137, 0.06670461, 0.0223763 , 0.24181654, 0.14236587,\n",
       "        0.04648372, 0.05839682, 0.05944144, 0.07808269, 0.20667065]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display the probability vectors for the first few images.\n",
    "# Every probability vector should add up to 1.\n",
    "predictions[:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 5.0%\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model.\n",
    "model2.evaluate(X_test, y_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
