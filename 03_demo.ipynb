{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Demo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Notebooks\n",
    "[01_data_visualization](01_data_visualization.ipynb)  \n",
    "[02_formulas](#2_formulas.ipynb)  \n",
    "[03_demo](03_demo.ipynb)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This Notebook's Contents\n",
    "[Model 1 Demo](#Model-1-Demo)  \n",
    "[Model 2 Demo](#Model-2-Demo)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import CIFAR-10 training data.\n",
    "from tensorflow.keras.datasets import cifar10\n",
    "(X_train, y_train), (X_test, y_test) = cifar10.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X_train: (50000, 32, 32, 3)\n",
      "Shape of X_test: (10000, 32, 32, 3)\n",
      "Shape of y_train: (50000, 1)\n",
      "Shape of y_test: (10000, 1)\n"
     ]
    }
   ],
   "source": [
    "# Display the shapes of the data.\n",
    "print(f'Shape of X_train: {X_train.shape}')\n",
    "print(f'Shape of X_test: {X_test.shape}')\n",
    "print(f'Shape of y_train: {y_train.shape}')\n",
    "print(f'Shape of y_test: {y_test.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the required modules.\n",
    "from hive_ml.layers.activation import ReluLayer\n",
    "from hive_ml.layers.convolution import ConvolutionLayer\n",
    "from hive_ml.layers.pooling import PoolLayer\n",
    "from hive_ml.layers.flatten import Flatten\n",
    "from hive_ml.layers.dense import DenseLayer\n",
    "from hive_ml.layers.loss import SoftmaxLayer\n",
    "from hive_ml.network import Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Downsize data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Downsize the training data in the interest of time.\n",
    "X_train = X_train[ :256, :, :, :]\n",
    "y_train = y_train[ :256, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Downsize test data.\n",
    "X_test = X_test[:50, :, :, :]\n",
    "y_test = y_test[:50, :]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model 1 Demo\n",
    "#### CONV => RELU => POOL => FLATTEN => DENSE => RELU => DENSE => SOFTMAX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the required modules.\n",
    "from hive_ml.layers.activation import ReluLayer\n",
    "from hive_ml.layers.convolution import ConvolutionLayer\n",
    "from hive_ml.layers.pooling import PoolLayer\n",
    "from hive_ml.layers.flatten import Flatten\n",
    "from hive_ml.layers.dense import DenseLayer\n",
    "from hive_ml.layers.loss import SoftmaxLayer\n",
    "from hive_ml.network import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate a model.\n",
    "model1 = Model(\n",
    "    ConvolutionLayer(filters=3, filter_size=3, padding=1, stride=1),\n",
    "    ReluLayer(),\n",
    "    PoolLayer(filter_size=2, stride=2, mode='max'),\n",
    "    Flatten(),\n",
    "    DenseLayer(units=100),\n",
    "    ReluLayer(),\n",
    "    DenseLayer(units=10),\n",
    "    SoftmaxLayer()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running epoch: 1\n",
      "Time to train 256 examples: 0.31 min.\n",
      "Loss epoch 1: 2.328\n",
      "Accuracy epoch 1: 10.938%\n"
     ]
    }
   ],
   "source": [
    "# Train the model.\n",
    "model1.train(X_train, y_train, 0.003, batch_size=256, epochs=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### *Loss when kicking off training should be $-log\\frac{1}{NumOfClasses}$, or ~2.3 in the case of CIFAR-10*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((50, 32, 32, 3), (50, 1))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Print shapes.\n",
    "X_test.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions.\n",
    "predictions = model1.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 50)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Print shapes.\n",
    "predictions.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transpose the predictions  from (num_classes, m) to (m, num_classes)\n",
    "predictions = predictions.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.08154513, 0.10089525, 0.10431777, 0.08111883, 0.10384669,\n",
       "        0.12426326, 0.12599579, 0.09445924, 0.09403178, 0.08952625],\n",
       "       [0.06757082, 0.10380369, 0.0953568 , 0.07312943, 0.0658482 ,\n",
       "        0.14104167, 0.13249581, 0.09182153, 0.09852298, 0.13040907],\n",
       "       [0.06549421, 0.10053562, 0.10211106, 0.06649677, 0.08149213,\n",
       "        0.15278903, 0.13538781, 0.05908225, 0.12019253, 0.11641859]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display the probability vectors for the first few images.\n",
    "# Every probability vector should add up to 1.\n",
    "predictions[:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 16.0%\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model.\n",
    "model1.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model 2 Demo\n",
    "#### CONV => RELU => POOL => CONV => RELU => POOL => FLATTEN => DENSE => RELU => DENSE => SOFTMAX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate a model.\n",
    "model2 = Model(\n",
    "    ConvolutionLayer(filters=5, filter_size=3, padding=1, stride=1),\n",
    "    ReluLayer(),\n",
    "    PoolLayer(filter_size=2, stride=2, mode='max'),\n",
    "    ConvolutionLayer(filters=7, filter_size=5, padding=2, stride=1),\n",
    "    ReluLayer(),\n",
    "    PoolLayer(filter_size=2, stride=2, mode='max'),\n",
    "    Flatten(),\n",
    "    DenseLayer(units=200),\n",
    "    ReluLayer(),\n",
    "    DenseLayer(units=100),\n",
    "    ReluLayer(),\n",
    "    DenseLayer(units=10),\n",
    "    SoftmaxLayer()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running epoch: 1\n",
      "Time to train 256 examples: 0.71 min.\n",
      "Loss epoch 1: 2.329\n",
      "Accuracy epoch 1: 7.031%\n"
     ]
    }
   ],
   "source": [
    "# Train the model.\n",
    "model2.train(X_train, y_train, 0.003, batch_size=64, epochs=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions.\n",
    "predictions = model2.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 50)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Print shape of predictions.\n",
    "predictions.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transpose the predictions  from (num_classes, m) to (m, num_classes).\n",
    "predictions = predictions.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.10413334, 0.12686349, 0.10847584, 0.09032921, 0.09930443,\n",
       "        0.0925857 , 0.08137928, 0.10447265, 0.09362743, 0.09882863],\n",
       "       [0.08765482, 0.10418482, 0.09602594, 0.09486345, 0.11701861,\n",
       "        0.09680303, 0.07810074, 0.12257822, 0.10505963, 0.09771075],\n",
       "       [0.09682733, 0.13272865, 0.1031384 , 0.09007281, 0.13909379,\n",
       "        0.08103277, 0.07007023, 0.10815612, 0.08230685, 0.09657305]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display the probability vectors for the first few images.\n",
    "# Every probability vector should add up to 1.\n",
    "predictions[:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 14.0%\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model.\n",
    "model2.evaluate(X_test, y_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
