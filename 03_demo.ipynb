{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import CIFAR-10 training data.\n",
    "from tensorflow.keras.datasets import cifar10\n",
    "(X_train, y_train), (X_test, y_test) = cifar10.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X_train: (50000, 32, 32, 3)\n",
      "Shape of X_test: (10000, 32, 32, 3)\n",
      "Shape of y_train: (50000, 1)\n",
      "Shape of y_test: (10000, 1)\n"
     ]
    }
   ],
   "source": [
    "# Display the shapes of the data.\n",
    "print(f'Shape of X_train: {X_train.shape}')\n",
    "print(f'Shape of X_test: {X_test.shape}')\n",
    "print(f'Shape of y_train: {y_train.shape}')\n",
    "print(f'Shape of y_test: {y_test.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the required modules.\n",
    "from hive_ml.layers.activation import ReluLayer\n",
    "from hive_ml.layers.convolution import ConvolutionLayer\n",
    "from hive_ml.layers.pooling import PoolLayer\n",
    "from hive_ml.layers.flatten import Flatten\n",
    "from hive_ml.layers.dense import DenseLayer\n",
    "from hive_ml.layers.loss import SoftmaxLayer\n",
    "from hive_ml.network import Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Downsize data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Downsize the training data in the interest of time.\n",
    "X_train = X_train[ :128, :, :, :]\n",
    "y_train = y_train[ :128, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Downsize test data.\n",
    "X_test = X_test[:100, :, :, :]\n",
    "y_test = y_test[:100, :]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model 1 Demo\n",
    "### CONV => RELU => POOL => FLATTEN => DENSE => DENSE => SOFTMAX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate a model.\n",
    "model1 = Model(\n",
    "    ConvolutionLayer(filters=3, filter_size=3, padding=1, stride=1),\n",
    "    ReluLayer(),\n",
    "    PoolLayer(filter_size=2, stride=2, mode='max'),\n",
    "    Flatten(),\n",
    "    DenseLayer(units=100),\n",
    "    DenseLayer(units=10),\n",
    "    SoftmaxLayer()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running epoch: 1\n",
      "Loss epoch 1: 2.3\n",
      "Accuracy epoch 1: 6.25%\n"
     ]
    }
   ],
   "source": [
    "# Train the model.\n",
    "model1.train(X_train, y_train, 0.003, batch_size=64, epochs=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((100, 32, 32, 3), (100, 1))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Print shapes.\n",
    "X_test.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions.\n",
    "predictions = model1.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 100)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Print shapes.\n",
    "predictions.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transpose the predictions  from (num_classes, m) to (m, num_classes)\n",
    "predictions = predictions.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.09996983, 0.09689765, 0.10622688, 0.09998797, 0.10211623,\n",
       "        0.09551045, 0.10637557, 0.09632385, 0.10443991, 0.09215166],\n",
       "       [0.09820449, 0.09673302, 0.10627269, 0.09938682, 0.09726872,\n",
       "        0.10034525, 0.09894379, 0.09654731, 0.11150986, 0.09478806],\n",
       "       [0.09967388, 0.09611584, 0.10531172, 0.10086124, 0.1018381 ,\n",
       "        0.09588142, 0.106078  , 0.09648658, 0.1043834 , 0.09336981]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display the probability vectors for the first few images.\n",
    "# Every probability vector should add up to 1.\n",
    "predictions[:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Probabilities vector shape: (10, 100)\n",
      "Y initial shape after to_categorical: (10, 100)\n",
      "Accuracy: 11.0%\n",
      "Probabilities final vector shape: (100, 10)\n",
      "Y_hat final shape (np.argmax(probs)): (100,)\n",
      "Y final shape (np.argmax(Y)): (100,)\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model.\n",
    "model1.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model 2 Demo\n",
    "### CONV => RELU => POOL => CONV => RELU => POOL => FLATTEN => DENSE => DENSE => SOFTMAX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate a model.\n",
    "model2 = Model(\n",
    "    ConvolutionLayer(filters=5, filter_size=3, padding=1, stride=1),\n",
    "    ReluLayer(),\n",
    "    PoolLayer(filter_size=2, stride=2, mode='max'),\n",
    "    ConvolutionLayer(filters=7, filter_size=5, padding=2, stride=1),\n",
    "    ReluLayer(),\n",
    "    PoolLayer(filter_size=2, stride=2, mode='max'),\n",
    "    Flatten(),\n",
    "    DenseLayer(units=200),\n",
    "    DenseLayer(units=100),\n",
    "    DenseLayer(units=10),\n",
    "    SoftmaxLayer()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running epoch: 1\n",
      "Loss epoch 1: 2.442\n",
      "Accuracy epoch 1: 7.031%\n"
     ]
    }
   ],
   "source": [
    "# Train the model.\n",
    "model2.train(X_train, y_train, 0.003, batch_size=64, epochs=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions.\n",
    "predictions = model2.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 100)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Print shape of predictions.\n",
    "predictions.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transpose the predictions  from (num_classes, m) to (m, num_classes).\n",
    "predictions = predictions.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.14262998, 0.07360996, 0.09054541, 0.1235078 , 0.08763813,\n",
       "        0.04686479, 0.03275856, 0.23076102, 0.08324209, 0.08844224],\n",
       "       [0.06483179, 0.16358901, 0.0199343 , 0.05467846, 0.10426319,\n",
       "        0.05885675, 0.15305129, 0.10540658, 0.20216226, 0.07322636],\n",
       "       [0.10791263, 0.06382466, 0.07055262, 0.05767116, 0.04909413,\n",
       "        0.19717906, 0.22574359, 0.06053172, 0.11335237, 0.05413805]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display the probability vectors for the first few images.\n",
    "# Every probability vector should add up to 1.\n",
    "predictions[:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Probabilities vector shape: (10, 100)\n",
      "Y initial shape after to_categorical: (10, 100)\n",
      "Accuracy: 5.0%\n",
      "Probabilities final vector shape: (100, 10)\n",
      "Y_hat final shape (np.argmax(probs)): (100,)\n",
      "Y final shape (np.argmax(Y)): (100,)\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model.\n",
    "model2.evaluate(X_test, y_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
